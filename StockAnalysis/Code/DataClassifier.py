# -*- coding: utf-8 -*-
"""CS561-Project

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MtcGIYlaXJo6ZULkQdukBsJeg2SE7m6o
"""

!pip install pyspark
!pip install -U -q PyDrive
!apt install openjdk-8-jdk-headless -qq
import os
os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-8-openjdk-amd64"

import numpy
import pandas as pd
import matplotlib.pyplot as plt
from pylab import *
import pyspark
from pyspark.sql.functions import udf, concat, col, lit
from pyspark.sql.types import IntegerType, ArrayType, StringType, DoubleType
import string
from pyspark.ml import Pipeline
from pyspark.ml.classification import RandomForestClassifier
from pyspark.ml.feature import StringIndexer, VectorIndexer, CountVectorizer, Tokenizer, StopWordsRemover, NGram
from pyspark.ml.evaluation import MulticlassClassificationEvaluator
from pyspark.ml.tuning import ParamGridBuilder
from pyspark.ml.tuning import CrossValidator
from pyspark.ml.evaluation import BinaryClassificationEvaluator
from pyspark import SparkConf, SparkContext

# create the session
conf = SparkConf().set("spark.ui.port", "4050")

# create the context
sc = pyspark.SparkContext(conf=conf)

sqlContext = pyspark.SQLContext(sc)

from google.colab import drive
drive.mount('/content/drive')

data = sqlContext.read.load('/content/drive/My Drive/final_dataset_tsla.csv', 
                          delimiter=',',
                          format='com.databricks.spark.csv', 
                          header='true', 
                          inferSchema='true')
print(data.show(n = 10))

def dataSplit(data):
  return data.randomSplit([0.7, 0.3]);

from pyspark.ml.feature import VectorAssembler
assembler = VectorAssembler(inputCols=['Score', 'Open', 'High', 'Low', 'Close'], outputCol='features')
data = assembler.transform(data)
print(data.show(n=10))

from pyspark.ml.classification import RandomForestClassifier
algo = RandomForestClassifier(featuresCol='features', labelCol='Result')
model = algo.fit(data)

predictions = model.transform(data)

predictions.select(['Result','prediction', 'probability']).show()

from pyspark.ml.evaluation import BinaryClassificationEvaluator
evaluator = BinaryClassificationEvaluator(labelCol='Result', metricName='areaUnderROC')

evaluator.evaluate(predictions)

y_true = predictions.select(['Result']).collect()
y_pred = predictions.select(['prediction']).collect()

from sklearn.metrics import classification_report, confusion_matrix
print(classification_report(y_true, y_pred))

print(confusion_matrix(y_true, y_pred))

from pyspark.ml.feature import VectorAssembler
assembler1 = VectorAssembler(inputCols=['Open', 'High', 'Low', 'Close'], outputCol='features1')
data1 = assembler1.transform(data)
print(data1.show(n=10))

from pyspark.ml.classification import RandomForestClassifier
algo1 = RandomForestClassifier(featuresCol='features1', labelCol='Result')
model1 = algo1.fit(data1)
predictions1 = model1.transform(data1)

from pyspark.ml.evaluation import BinaryClassificationEvaluator
evaluator1 = BinaryClassificationEvaluator(labelCol='Result', metricName='areaUnderROC')
evaluator1.evaluate(predictions1)

print("Done")

